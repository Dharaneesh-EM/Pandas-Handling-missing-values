{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharaneesh-EM/Pandas-Handling-missing-values/blob/main/exp1_6_ip_Dharaneesh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uda-fxyeZwCE",
        "outputId": "57a8dc3f-64b2-4d59-d144-1e2f4cd16aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 1:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Exercise 1: Create a MultiIndex from a DataFrame\n",
        "arrays = [['A', 'A', 'B', 'B'], [1, 2, 1, 2]]\n",
        "index = pd.MultiIndex.from_arrays(arrays, names=('letters', 'numbers'))\n",
        "df = pd.DataFrame({'values': [10, 20, 30, 40]}, index=index)\n",
        "print(\"Exercise 1:\\n\", df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVHEvWkwayue"
      },
      "source": [
        "Exercise 1: Create a MultiIndex from a DataFrame\n",
        "from_arrays() is used to create a MultiIndex with two levels: letters and numbers.\n",
        "The DataFrame is indexed using this MultiIndex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVnQpEzNa05s",
        "outputId": "da82aab7-f13f-4c3f-fab0-1700048dbd3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exercise 2:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2: Create a MultiIndex using from_tuples()\n",
        "arrays = [('A', 1), ('A', 2), ('B', 1), ('B', 2)]\n",
        "index = pd.MultiIndex.from_tuples(arrays, names=('letters', 'numbers'))\n",
        "df = pd.DataFrame({'values': [10, 20, 30, 40]}, index=index)\n",
        "print(\"\\nExercise 2:\\n\", df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poBkZw2sa3nT"
      },
      "source": [
        "Exercise 2: Create a MultiIndex using from_tuples()\n",
        "Instead of arrays, we use tuples to define the MultiIndex structure.\n",
        "The result is similar to Exercise 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5EcycbFa8Ms",
        "outputId": "7f5e52e2-8f1a-4a55-b4be-95b19a92c4ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exercise 3:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ],
      "source": [
        "# Exercise 3: Create a MultiIndex using from_product()\n",
        "index = pd.MultiIndex.from_product([['A', 'B'], [1, 2]], names=('letters', 'numbers'))\n",
        "df = pd.DataFrame({'values': [10, 20, 30, 40]}, index=index)\n",
        "print(\"\\nExercise 3:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CwP7LanbEu8"
      },
      "source": [
        "Exercise 3: Create a MultiIndex using from_product()\n",
        "Generates all possible combinations of two lists using from_product().\n",
        "This ensures structured hierarchical indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQPTxS2MbGyE",
        "outputId": "9bf747f8-af78-42de-9145-1ce326e22375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exercise 4:\n",
            "                  values\n",
            "letters numbers        \n",
            "A       1            10\n",
            "        2            20\n",
            "B       1            30\n",
            "        2            40\n"
          ]
        }
      ],
      "source": [
        "# Exercise 4: Create a MultiIndex using set_index()\n",
        "df = pd.DataFrame({'letters': ['A', 'A', 'B', 'B'], 'numbers': [1, 2, 1, 2], 'values': [10, 20, 30, 40]})\n",
        "df = df.set_index(['letters', 'numbers'])\n",
        "print(\"\\nExercise 4:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHujeDPzbIz1"
      },
      "source": [
        "Exercise 5: Remove index levels from a MultiIndex\n",
        "reset_index() removes the MultiIndex and turns them back into columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "collapsed": true,
        "id": "Flq2nV8KbK2c",
        "outputId": "328116c6-98ad-49b0-a1f2-ea79e268a454"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"None of ['letters', 'numbers'] are in the columns\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-da853cd3db42>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Exercise 6: Sort a MultiIndex DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'letters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numbers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nExercise 6:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of ['letters', 'numbers'] are in the columns\""
          ]
        }
      ],
      "source": [
        "# Exercise 6: Sort a MultiIndex DataFrame\n",
        "df = df.set_index(['letters', 'numbers']).sort_index()\n",
        "print(\"\\nExercise 6:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl4VeNXebPhz"
      },
      "source": [
        "Exercise 6: Sort a MultiIndex DataFrame\n",
        "sort_index() sorts the MultiIndex in ascending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X68TS71LbWHt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "df = df.swaplevel()\n",
        "print(\"\\nExercise 7:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BtM05Zybcm0"
      },
      "source": [
        "Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "swaplevel() swaps the two index levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D31OCJlWbe1c"
      },
      "outputs": [],
      "source": [
        "## Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "df = df.swaplevel()\n",
        "print(\"\\nExercise 7:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeLYCVT_bvhm"
      },
      "source": [
        "Exercise 7: Swap levels in a MultiIndex DataFrame\n",
        "swaplevel() swaps the two index levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0mrf9vbbxEk"
      },
      "outputs": [],
      "source": [
        "# Exercise 8: Select a specific subset from a MultiIndex DataFrame\n",
        "print(\"\\nExercise 8:\\n\", df.loc['A'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFHlbIuVbzwM"
      },
      "source": [
        "Exercise 8: Select a specific subset from a MultiIndex DataFrame\n",
        ".loc[] is used to select all rows where the first index level is 'A'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8VE4LMRcKxc"
      },
      "outputs": [],
      "source": [
        "# Exercise 9: Perform a cross-section (xs) on a MultiIndex DataFrame\n",
        "print(\"\\nExercise 9:\\n\", df.xs(1, level='numbers'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RISKzVLOcMps"
      },
      "source": [
        "Exercise 9: Perform a cross-section (xs()) on a MultiIndex DataFrame\n",
        "xs() extracts all rows where the numbers index level is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sjuUe0TcOj1"
      },
      "outputs": [],
      "source": [
        "# Exercise 10: Apply a function to a level in a MultiIndex DataFrame\n",
        "df['values'] = df['values'].groupby(level='letters').transform(lambda x: x * 2)\n",
        "print(\"\\nExercise 10:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQaqszbOcQT7"
      },
      "source": [
        "Exercise 10: Apply a function to a level in a MultiIndex DataFrame\n",
        "Groups the values column by letters and multiplies them by 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "983ijR_kcRuN"
      },
      "outputs": [],
      "source": [
        "# Exercise 11: Rename MultiIndex levels\n",
        "df = df.rename_axis(index={'letters': 'alpha', 'numbers': 'num'})\n",
        "print(\"\\nExercise 11:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vjeIvtwcUdt"
      },
      "source": [
        "Exercise 11: Rename MultiIndex levels\n",
        "rename_axis() renames the index levels from letters ΓåÆ alpha and numbers ΓåÆ num."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t9RHy-6cXWc"
      },
      "outputs": [],
      "source": [
        "# Exercise 12: Remove a level from MultiIndex using droplevel()\n",
        "df = df.droplevel('num')\n",
        "print(\"\\nExercise 12:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIlYN-7vcfQc"
      },
      "source": [
        "Exercise 12: Remove a level from MultiIndex using droplevel()\n",
        "droplevel('num') removes the numbers index level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFToSoLTciaV"
      },
      "source": [
        "# Exercise 13: Check for uniqueness in MultiIndex DataFrame\n",
        "print(\"\\nExercise 13:\\n\", df.index.is_unique)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltS6-3zCclHk"
      },
      "source": [
        "Exercise 13: Check for uniqueness in MultiIndex DataFrame\n",
        "df.index.is_unique checks if each index combination is unique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_agtRKtcoh8"
      },
      "outputs": [],
      "source": [
        "# Exercise 14: Convert a MultiIndex DataFrame to a flat DataFrame\n",
        "df = df.reset_index()\n",
        "print(\"\\nExercise 14:\\n\", df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkvp4KIocqoc"
      },
      "source": [
        "Exercise 14: Convert a MultiIndex DataFrame to a flat DataFrame\n",
        "reset_index() is used again to flatten the MultiIndex into regular columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9AzpdJ6ctzN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Exercise 15: Create a Pivot Table from a MultiIndex DataFrame\n",
        "df = pd.DataFrame({'letters': ['A', 'A', 'B', 'B'], 'numbers': [1, 2, 1, 2], 'values': [10, 20, 30, 40]})\n",
        "pivot_table = df.pivot_table(values='values', index='letters', columns='numbers', aggfunc='sum')\n",
        "print(\"\\nExercise 15:\\n\", pivot_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzc79hQFcwnV"
      },
      "source": [
        "Exercise 15: Create a Pivot Table from a MultiIndex DataFrame\n",
        "pivot_table() restructures the DataFrame, organizing values by letters and numbers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdjo3uqtcy8d"
      },
      "source": [
        "Pandas Filter [ 27 exercises with solution ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHcD-jkqc3G0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n",
        "print(\"\\nType of the object:\")\n",
        "print(type(result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52_Y7Qm1fhsG"
      },
      "source": [
        "Groups the DataFrame by column 'A' and counts the number of rows in each group.\n",
        "This is useful for understanding how frequently each category appears in the dataset. It helps summarize categorical data efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJkyfqX-fi79"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n",
        "print(\"\\nType of the object:\")\n",
        "print(type(result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT6LPVXjfnat"
      },
      "source": [
        "Groups the DataFrame by multiple columns ('A' and 'B') and counts the number of occurrences for each combination.\n",
        "This allows analyzing relationships between multiple categorical variables and identifying common patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDBPVIpkfol1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code, class wise:')\n",
        "result = student_data.groupby(['school_code', 'class'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCKoOw35f16a"
      },
      "source": [
        "Groups the DataFrame by column 'A' and calculates the sum of numeric columns for each group.\n",
        "This is useful when aggregating transaction amounts, total sales, or any other measurable quantities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJdtXWTJf4bm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nCast grouping as a list:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "print(list(result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OQxJjpZgDc6"
      },
      "source": [
        "Groups the DataFrame by column 'A' and calculates the sum of numeric columns for each group.\n",
        "This is useful when aggregating transaction amounts, total sales, or any other measurable quantities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL0kWxk7gHb2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nCast grouping as a list:')\n",
        "result = student_data.groupby(['school_code'])\n",
        "print(list(result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2ye7y_tgL4n"
      },
      "source": [
        "Finds the mean of numeric columns for each unique group in column 'A'.\n",
        "This helps in understanding the average values per category, useful in analyzing trends like average sales or performance per group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ZglmrJgOy-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "grouped_single = student_data.groupby(['school_code'])\n",
        "print(\"Size of the grouped data - single column\")\n",
        "print(grouped_single.size())\n",
        "print('\\nSplit the said data on school_code and class wise:')\n",
        "\n",
        "grouped_mul = student_data.groupby(['school_code', 'class'])\n",
        "print(\"Size of the grouped data - multiple columns:\")\n",
        "print(grouped_mul.size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfqmUiBngUom"
      },
      "source": [
        "Applies multiple aggregation functions (like sum, mean) to grouped data at once.\n",
        "This allows retrieving multiple summary statistics efficiently without requiring multiple groupby operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jQrTt2IgVKt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nSplit the said data on school_code wise:')\n",
        "grouped = student_data.groupby(['school_code'])\n",
        "print(\"Call school code 's001':\")\n",
        "print(grouped.get_group('s001'))\n",
        "print(\"\\nCall school code 's004':\")\n",
        "print(grouped.get_group('s004'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgd93qeYgbIm"
      },
      "source": [
        "Filters out groups where the sum of column 'C' is less than or equal to 3.\n",
        "This helps in keeping only significant groups that meet a certain threshold, useful in financial and business analytics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n3AZjlagdcW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "orders_data = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(orders_data)\n",
        "result = orders_data.groupby('customer_id').agg({'purch_amt': ['mean', 'min', 'max']})\n",
        "print(\"\\nMean, min, and max values of purchase amount (purch_amt) group by customer id  (customer_id).\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHflx8HKgg7Q"
      },
      "source": [
        "Iterates over grouped DataFrame, printing each group separately.\n",
        "This helps inspect each category and its corresponding data, which is useful for debugging or exploratory analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZxnnicJgiuu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "orders_data = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(orders_data)\n",
        "print(\"\\nGroup by two columns and count by each row:\")\n",
        "result = orders_data.groupby(['salesman_id','customer_id']).size().reset_index().groupby(['salesman_id','customer_id'])[[0]].max()\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQG_3OvsgmIO"
      },
      "source": [
        "Transforms column 'C' by subtracting the mean of 'C' within each group.\n",
        "This normalization method helps in making data comparable within groups, which is useful for statistical modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ndmoPkKgojX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "df_agg = df.groupby(['customer_id','salesman_id']).agg({'purch_amt':sum})\n",
        "result = df_agg['purch_amt'].groupby(level=0, group_keys=False)\n",
        "print(\"\\nGroup on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups:\")\n",
        "print(result.nlargest())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ0mIOL2grRd"
      },
      "source": [
        "Computes the percentage of each value in column 'C' relative to the groupΓÇÖs total.\n",
        "This is useful for analyzing the proportion of a categoryΓÇÖs contribution within a group, such as percentage sales per region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iD_QCWXgtHv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby('customer_id')['ord_date'].apply(list)\n",
        "print(\"\\nGroup on 'customer_id' and display the list of order dates in group wise:\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFeDmHrUgwIf"
      },
      "source": [
        "Finds the largest n values in column 'C' for each group.\n",
        "This is helpful for ranking items within categories, such as identifying the top-selling products in each region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC7O5WZGg0K-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "df['ord_date']= pd.to_datetime(df['ord_date'])\n",
        "print(\"\\nMonth wise purchase amount:\")\n",
        "result = df.set_index('ord_date').groupby(pd.Grouper(freq='M')).agg({'purch_amt':sum})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNFvFlH2g2rs"
      },
      "source": [
        "Creates a pivot table summarizing column 'C' values grouped by column 'A'.\n",
        "Pivot tables make it easier to visualize aggregated data and analyze trends across different groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRhxTDDDhC5O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2013','08-17-2013','10-09-2013','07-27-2014','10-09-2012','10-10-2012','10-10-2012','06-17-2014','07-08-2012','04-25-2012'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "df['ord_date']= pd.to_datetime(df['ord_date'])\n",
        "print(\"\\nYear wise Month wise purchase amount:\")\n",
        "result = df.groupby([df['ord_date'].dt.year, df['ord_date'].dt.month]).agg({'purch_amt':sum})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT8tWcMVhFoP"
      },
      "source": [
        "Computes the cumulative sum of column 'C' within each group.\n",
        "This is used to track running totals, such as cumulative sales or stock levels over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s73ldhQhHku"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'X' : [10, 10, 10, 20, 30, 30, 10],\n",
        "                    'Y' : [10, 15, 11, 20, 21, 12, 14],\n",
        "                    'Z' : [22, 20, 18, 20, 13, 10, 0]})\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "result= df.groupby('X').aggregate(lambda tdf: tdf.unique().tolist())\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh_JMlaQhLXl"
      },
      "source": [
        "Fills missing values in column 'C' using the mean of 'C' for each group.\n",
        "This method ensures missing data does not skew analysis, especially useful in machine learning preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7t4bOC3hM82"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'id' : [1, 2, 1, 1, 2, 1, 2],\n",
        "                    'type' : [10, 15, 11, 20, 21, 12, 14],\n",
        "                    'book' : ['Math','English','Physics','Math','English','Physics','English']})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby(['id', 'type', 'book']).size().unstack(fill_value=0)\n",
        "print(\"\\nResult:\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpYv8HLThSDV"
      },
      "source": [
        "Ranks values in column 'C' within each group.\n",
        "This assigns a ranking to each value, useful in competitions, sales leaderboards, and percentile calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqoA6mF0hUDy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'id' : [1, 2, 1, 1, 2, 1, 2],\n",
        "                    'type' : [10, 15, 11, 20, 21, 12, 14],\n",
        "                    'book' : ['Math','English','Physics','Math','English','Physics','English']})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby(['id', 'type', 'book']).size().unstack(fill_value=0)\n",
        "print(\"\\nResult:\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43j9BHpphej2"
      },
      "source": [
        "Retrieves the first row from each group.\n",
        "This is useful when extracting initial transactions, earliest dates, or first occurrences of events per category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxRTsEt5hgye"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "df = pd.DataFrame({\n",
        "'book_name':['Book1','Book2','Book3','Book4','Book1','Book2','Book3','Book5'],\n",
        "'book_type':['Math','Physics','Computer','Science','Math','Physics','Computer','English'],\n",
        "'book_id':[1,2,3,4,1,2,3,5]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nNew column with count from groupby:\")\n",
        "result = df.groupby([\"book_name\", \"book_type\"])[\"book_type\"].count().reset_index(name=\"count\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMrfEjeThkJm"
      },
      "source": [
        "Counts the number of unique values in column 'C' within each group.\n",
        "This helps analyze the diversity of values in each category, such as unique products sold per store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNMMfJKThoiu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'sales_id':[5002,5003,5004,5003,5002,5001,5005,5007,5008,5004,5005,5001]})\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "groups = df.groupby(['customer_id', pd.cut(df.sales_id, 3)])\n",
        "result = groups.size().unstack()\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA_TP-vZhr7-"
      },
      "source": [
        "Filters out groups that have only one row, keeping only those with multiple records.\n",
        "This is useful for analyzing repeated events and ignoring single-instance occurrences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFWnBse4ht3e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s001'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nGroup by with multiple aggregations:\")\n",
        "result = df.groupby(['school_code','class']).agg({'height': ['max', 'mean'],\n",
        "                                 'weight': ['sum','min','count']})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seJgq28_hw1O"
      },
      "source": [
        "Finds the minimum and maximum value of column 'C' in each group.\n",
        "This helps determine the range of values within a category, such as lowest and highest prices per brand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmFnu5pLhyse"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( {'id' : ['A','A','A','A','A','A','B','B','B','B','B'],\n",
        "                    'type' : [1,1,1,1,2,2,1,1,1,2,2],\n",
        "                    'book' : ['Math','Math','English','Physics','Math','English','Physics','English','Physics','English','English']})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "new_df = df[['id', 'type', 'book']].drop_duplicates()\\\n",
        "                         .groupby(['id','type'])['book']\\\n",
        "                         .apply(list)\\\n",
        "                         .reset_index()\n",
        "\n",
        "new_df['book'] = new_df.apply(lambda x: (','.join([str(s) for s in x['book']])), axis = 1)\n",
        "print(\"\\nList all unique values in a group:\")\n",
        "print(new_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_KZfcICh2MF"
      },
      "source": [
        "Counts the number of missing values in each group.\n",
        "This helps in data cleaning by identifying categories with high levels of missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pabOMCZlh5s2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    ' height ': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)\n",
        "print('\\nMean, min, and max value of age for each school with customized column names:')\n",
        "grouped_single = student_data.groupby('school_code').agg(Age_Mean = ('age','mean'),Age_Max=('age',max),Age_Min=('age',min))\n",
        "print(grouped_single)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvL4XPzDh_zA"
      },
      "source": [
        "Computes the median of column 'C' within each group.\n",
        "The median is useful when analyzing skewed data, such as income distributions within different demographics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySzShkiQiEHn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':['C3001','C3001','D3005','D3001','C3005','D3001','C3005','D3001','D3005','C3001','D3005','D3005'],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "def customer_id_C(x):\n",
        "    return (x.str[0] == 'C').sum()\n",
        "result = df.groupby(['salesman_id'])\\\n",
        "  .agg(customer_id_start_C = ('customer_id', customer_id_C),\n",
        "       customer_id_list = ('customer_id', lambda x: ', '.join(x)),\n",
        "       purchase_amt_gap   = ('purch_amt', lambda x: x.max()-x.min())\n",
        "      )\n",
        "print(\"\\nNumber of customers  starting with ΓÇÿCΓÇÖ, the list of all products and the difference of maximum purchase amount and minimum purchase amount:\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_OWqxcYiH7O"
      },
      "source": [
        "Finds the variance of column 'C' within each group.\n",
        "Variance measures data dispersion, helping understand consistency within groups, such as customer spending habits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwMCk3HaiKU-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "gr_data = df.groupby(['customer_id','salesman_id']).agg({'purch_amt': 'sum'})\n",
        "gr_data[\"% (Purch Amt.)\"] = gr_data.apply(lambda x:  100*x / x.sum())\n",
        "print(\"\\nPercentage of purch_amt in each group of customer_id:\")\n",
        "print(gr_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lookgJMoiOu3"
      },
      "source": [
        "Computes the standard deviation of column 'C' within each group.\n",
        "Standard deviation is useful for analyzing volatility, such as stock price fluctuations within different sectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqT9GjpFiSW_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "dict_data_list = list()\n",
        "\n",
        "for gg, dd in df.groupby(['school_code','class']):\n",
        "    group = dict(zip(['school_code','class'], gg))\n",
        "    ocolumns_list = list()\n",
        "    for _, data in dd.iterrows():\n",
        "        data = data.drop(labels=['school_code','class'])\n",
        "        ocolumns_list.append(data.to_dict())\n",
        "    group['other_columns'] = ocolumns_list\n",
        "    dict_data_list.append(group)\n",
        "\n",
        "print(dict_data_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1t9hLXgiXtU"
      },
      "source": [
        "Creates a new column storing the mean of 'C' for each group.\n",
        "This is useful for comparing each value to its groupΓÇÖs average, helping in anomaly detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LckZU3u3iZH3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001],\n",
        "'sale_jan':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 1760, 2983.43, 480.4,  1250.45, 75.29,1045.6],\n",
        "'sale_feb':[250.5, 170.65, 15.26, 110.5, 598.5, 1400.6, 2760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_mar':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_apr':[150.5, 270.65, 95.26, 210.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_may':[130.5, 270.65, 65.26, 310.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_jun':[150.5, 270.65, 45.26, 110.5, 948.5, 3400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_jul':[950.5, 270.65, 65.26, 210.5, 948.5, 2400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_aug':[150.5, 70.65,  65.26, 110.5, 948.5, 400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_sep':[150.5, 270.65, 65.26, 110.5, 948.5, 200.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_oct':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_nov':[150.5, 270.65, 95.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_dec':[150.5, 70.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6]\n",
        "})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\Result after group on salesman_id and apply different aggregate functions:\")\n",
        "df = df.groupby('salesman_id').agg(lambda x : x.sum() if x.name in ['sale_jan','sale_feb','sale_mar'] else x.mean())\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LAkI27hijlX"
      },
      "source": [
        "Computes a rolling mean of column 'C' within each group.\n",
        "Rolling means smooth out fluctuations over a moving window, useful in trend analysis like sales forecasts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7aJZtTPikBf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'salesman_id': [5001,5002,5003,5004,5005,5006,5007,5008,5009,5010,5011,5012],\n",
        "'sale_jan':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 1760, 2983.43, 480.4,  1250.45, 75.29,1045.6]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "result = df.groupby(pd.cut(df['salesman_id'],\n",
        "                  bins=[0,5006,np.inf],\n",
        "                  labels=['S1', 'S2']))['sale_jan'].sum().reset_index()\n",
        "print(\"\\nGroupBy with condition of  two labels and ranges:\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlcggIJmin2P"
      },
      "source": [
        "Computes an expanding sum of column 'C' within each group.\n",
        "Expanding sums show cumulative growth, such as total revenue over time for different regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgpC2Y3wisvQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "    'student_id': ['S001','S001','S002','S002','S003','S003'],\n",
        "    'marks': [[88,89,90],[78,81,60],[84,83,91],[84,88,91],[90,89,92],[88,59,90]]})\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nGroupby and aggregate over multiple lists:\")\n",
        "result = df.set_index('student_id')['marks'].groupby('student_id').apply(list).apply(lambda x: np.mean(x,0))\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BIihFD6i80K"
      },
      "source": [
        "Finds the correlation between columns 'B' and 'C' within each group.\n",
        "Correlation analysis helps understand relationships, such as whether increased marketing ('B') affects sales ('C').\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNzhburpi_Gn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5004,5003,5002,5004,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nGroupby to find first order date for each group(salesman_id):\")\n",
        "result = df.groupby('salesman_id')['ord_date'].min()\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uknQUmtejDbQ"
      },
      "source": [
        "Computes the cumulative product of column 'C' within each group.\n",
        "This is useful for scenarios involving continuous growth rates, such as compound interest or population growth.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r39BrUkZjF8f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3002,3001,3001,3003,3002,3002,3001,3004,3003,3002,3003,3001],\n",
        "'salesman_id':[5002,5003,5001,5003,5002,5001,5001,5003,5003,5002,5003,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nSplit the said data on 'salesman_id', 'customer_id' wise:\")\n",
        "result = df.groupby(['salesman_id', 'customer_id'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n",
        "n = 2\n",
        "#result1 = df.groupby(['salesman_id', 'customer_id']).tail(n).index, axis=0)\n",
        "print(\"\\nDroping last two records:\")\n",
        "result1 = df.drop(df.groupby(['salesman_id', 'customer_id']).tail(n).index, axis=0)\n",
        "print(result1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh2zPq11jKBG"
      },
      "source": [
        "Finds the most frequent (mode) value of column 'C' within each group.\n",
        "The mode identifies the most common occurrence, such as the most popular product purchased per store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omE--uE-aM08"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSKW_3tuanzB"
      },
      "source": [
        "1.Detect Missing Values: Identify missing values in a DataFrame and display them as a boolean DataFrame, where True indicates a missing value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS3aCgeTbckr"
      },
      "source": [
        "EXERCISE 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-ddLvhfdP0z",
        "outputId": "e1fea069-0227-4189-a9d4-185f48c05c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the dataset: (100, 5)\n",
            "Column names: ['Year', 'WHO region', 'Country', 'Beverage Types', 'Display Value']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Display the shape and column names\n",
        "print(\"Shape of the dataset:\", df.shape)\n",
        "print(\"Column names:\", df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCPFJcxpefLQ"
      },
      "source": [
        "Loads the dataset and prints its dimensions and column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxSIgSPyepK1",
        "outputId": "bd80bd1a-dd3a-4af5-dfb1-e767afaac1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Year       WHO region\n",
            "0  1986  Western Pacific\n",
            "1  1986         Americas\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "#Select first 2 rows and first 2 columns\n",
        "result = df.iloc[:2, :2]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZObwNv5pelMB"
      },
      "source": [
        "Retrieves the first two rows and first two columns of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hsw3MA2dO6m"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSi_VNOMeqYI",
        "outputId": "65fcf316-56c1-4bd0-d07b-c83a548f826c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random 5 rows:\n",
            "     Year       WHO region                                Country  \\\n",
            "76  1985           Africa                                Comoros   \n",
            "6   1987           Africa                              Mauritius   \n",
            "2   1985           Africa                           Cte d'Ivoire   \n",
            "99  1985  South-East Asia  Democratic People's Republic of Korea   \n",
            "92  1986           Africa                                Eritrea   \n",
            "\n",
            "   Beverage Types  Display Value  \n",
            "76           Beer           0.02  \n",
            "6            Wine           0.13  \n",
            "2            Wine           1.62  \n",
            "99           Wine           0.00  \n",
            "92        Spirits           0.00  \n",
            "Random 10% rows:\n",
            "     Year             WHO region            Country Beverage Types  \\\n",
            "10  1987                 Africa           Botswana           Wine   \n",
            "0   1986        Western Pacific           Viet Nam           Wine   \n",
            "88  1987  Eastern Mediterranean            Lebanon           Beer   \n",
            "69  1986                 Africa               Togo        Spirits   \n",
            "98  1984                 Africa  Equatorial Guinea           Wine   \n",
            "92  1986                 Africa            Eritrea        Spirits   \n",
            "51  1987                 Europe            Finland           Beer   \n",
            "38  1987  Eastern Mediterranean              Qatar          Other   \n",
            "45  1989                 Africa           Zimbabwe           Beer   \n",
            "1   1986               Americas            Uruguay          Other   \n",
            "\n",
            "    Display Value  \n",
            "10           0.20  \n",
            "0            0.00  \n",
            "88           0.42  \n",
            "69           0.42  \n",
            "98           0.00  \n",
            "92           0.00  \n",
            "51           3.88  \n",
            "38           0.00  \n",
            "45           0.19  \n",
            "1            0.50  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Select a random sample of 5 rows\n",
        "random_rows = df.sample(n=5)\n",
        "print(\"Random 5 rows:\\n\", random_rows)\n",
        "\n",
        "# Select 10% random rows\n",
        "fraction_rows = df.sample(frac=0.1)\n",
        "print(\"Random 10% rows:\\n\", fraction_rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T50ubjpeufF"
      },
      "source": [
        "Randomly selects 5 rows and then 10% of the rows from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zvjSJYievtI",
        "outputId": "607f5291-612f-456f-d829-178c16f8472f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in each column:\n",
            " Year              0\n",
            "WHO region        0\n",
            "Country           0\n",
            "Beverage Types    0\n",
            "Display Value     5\n",
            "dtype: int64\n",
            "Dataset after dropping missing values:\n",
            "     Year       WHO region                                Country  \\\n",
            "0   1986  Western Pacific                               Viet Nam   \n",
            "1   1986         Americas                                Uruguay   \n",
            "2   1985           Africa                           Cte d'Ivoire   \n",
            "3   1986         Americas                               Colombia   \n",
            "4   1987         Americas                  Saint Kitts and Nevis   \n",
            "..   ...              ...                                    ...   \n",
            "95  1984           Africa                                  Niger   \n",
            "96  1985           Europe                             Luxembourg   \n",
            "97  1984  South-East Asia                              Indonesia   \n",
            "98  1984           Africa                      Equatorial Guinea   \n",
            "99  1985  South-East Asia  Democratic People's Republic of Korea   \n",
            "\n",
            "   Beverage Types  Display Value  \n",
            "0            Wine           0.00  \n",
            "1           Other           0.50  \n",
            "2            Wine           1.62  \n",
            "3            Beer           4.27  \n",
            "4            Beer           1.98  \n",
            "..            ...            ...  \n",
            "95          Other           0.00  \n",
            "96           Wine           7.38  \n",
            "97           Wine           0.00  \n",
            "98           Wine           0.00  \n",
            "99           Wine           0.00  \n",
            "\n",
            "[95 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column:\\n\", missing_values)\n",
        "\n",
        "# Drop rows with missing values\n",
        "df_cleaned = df.dropna()\n",
        "print(\"Dataset after dropping missing values:\\n\", df_cleaned)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2Pt08r_exij"
      },
      "source": [
        "Identifies and removes rows with missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ziMiq_EezsT",
        "outputId": "dd5a5b5d-5bcc-4c92-bddc-623bf314e784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset with unique WHO regions:\n",
            "     Year             WHO region       Country Beverage Types  Display Value\n",
            "0   1986        Western Pacific      Viet Nam           Wine           0.00\n",
            "1   1986               Americas       Uruguay          Other           0.50\n",
            "2   1985                 Africa  Cte d'Ivoire           Wine           1.62\n",
            "13  1984  Eastern Mediterranean   Afghanistan          Other           0.00\n",
            "18  1984                 Europe        Norway        Spirits           1.62\n",
            "20  1986        South-East Asia       Myanmar           Wine           0.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Remove duplicates based on 'WHO region' column\n",
        "df_unique_regions = df.drop_duplicates(subset='WHO region')\n",
        "print(\"Dataset with unique WHO regions:\\n\", df_unique_regions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyUOGAQie1WT"
      },
      "source": [
        "Eliminates duplicate entries in the 'WHO region' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z1f4tzme36u",
        "outputId": "43e68422-5117-48a8-a327-9716355c0148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for the year 1986:\n",
            "     Year             WHO region                           Country  \\\n",
            "0   1986        Western Pacific                          Viet Nam   \n",
            "1   1986               Americas                           Uruguay   \n",
            "3   1986               Americas                          Colombia   \n",
            "8   1986               Americas               Antigua and Barbuda   \n",
            "20  1986        South-East Asia                           Myanmar   \n",
            "29  1986                 Europe                             Italy   \n",
            "30  1986                 Africa                      Sierra Leone   \n",
            "31  1986        Western Pacific  Micronesia (Federated States of)   \n",
            "34  1986                 Europe                Russian Federation   \n",
            "37  1986                 Europe                            Sweden   \n",
            "41  1986                 Europe                    Czech Republic   \n",
            "47  1986               Americas                            Mexico   \n",
            "49  1986                 Europe                             Malta   \n",
            "52  1986  Eastern Mediterranean                      Saudi Arabia   \n",
            "69  1986                 Africa                              Togo   \n",
            "70  1986                 Africa                        Madagascar   \n",
            "73  1986  Eastern Mediterranean                          Pakistan   \n",
            "74  1986               Americas  Bolivia (Plurinational State of)   \n",
            "83  1986                 Europe                           Ukraine   \n",
            "84  1986        South-East Asia                         Sri Lanka   \n",
            "86  1986               Americas                           Bahamas   \n",
            "89  1986  Eastern Mediterranean                           Lebanon   \n",
            "92  1986                 Africa                           Eritrea   \n",
            "\n",
            "   Beverage Types  Display Value  \n",
            "0            Wine           0.00  \n",
            "1           Other           0.50  \n",
            "3            Beer           4.27  \n",
            "8         Spirits           1.55  \n",
            "20           Wine           0.00  \n",
            "29          Other            NaN  \n",
            "30          Other           4.48  \n",
            "31           Wine           0.00  \n",
            "34           Wine           0.80  \n",
            "37           Beer           3.04  \n",
            "41           Beer           6.82  \n",
            "47          Other           0.04  \n",
            "49           Wine           1.49  \n",
            "52           Wine           0.00  \n",
            "69        Spirits           0.42  \n",
            "70        Spirits           1.02  \n",
            "73          Other           0.01  \n",
            "74        Spirits           2.06  \n",
            "83          Other            NaN  \n",
            "84          Other           0.00  \n",
            "86           Wine           1.83  \n",
            "89           Wine           0.70  \n",
            "92        Spirits           0.00  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows for the year 1986\n",
        "df_1986 = df[df['Year'] == 1986]\n",
        "print(\"Data for the year 1986:\\n\", df_1986)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naPQq_g1e5wG"
      },
      "source": [
        "Filters and displays data corresponding to the year 1986."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m4JIB4qe7Ow",
        "outputId": "1afc394f-2a45-4e6b-fd47-044050e335cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for Viet Nam:\n",
            "     Year       WHO region   Country Beverage Types  Display Value\n",
            "0   1986  Western Pacific  Viet Nam           Wine           0.00\n",
            "14  1985  Western Pacific  Viet Nam        Spirits           0.05\n",
            "28  1987  Western Pacific  Viet Nam           Beer           0.11\n",
            "56  1987  Western Pacific  Viet Nam           Wine           0.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows for 'Viet Nam'\n",
        "df_vietnam = df[df['Country'] == 'Viet Nam']\n",
        "print(\"Data for Viet Nam:\\n\", df_vietnam)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBEMtMQGe9Ua"
      },
      "source": [
        "Retrieves data entries specific to 'Viet Nam'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tliRs6HHe--v",
        "outputId": "2a211e6d-59c4-4aaa-f500-e0beca37ae1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for Western Pacific region:\n",
            "     Year       WHO region                           Country Beverage Types  \\\n",
            "0   1986  Western Pacific                          Viet Nam           Wine   \n",
            "12  1985  Western Pacific  Lao People's Democratic Republic           Beer   \n",
            "14  1985  Western Pacific                          Viet Nam        Spirits   \n",
            "28  1987  Western Pacific                          Viet Nam           Beer   \n",
            "31  1986  Western Pacific  Micronesia (Federated States of)           Wine   \n",
            "43  1984  Western Pacific                             China           Wine   \n",
            "56  1987  Western Pacific                          Viet Nam           Wine   \n",
            "61  1984  Western Pacific                  Papua New Guinea        Spirits   \n",
            "\n",
            "    Display Value  \n",
            "0            0.00  \n",
            "12           0.00  \n",
            "14           0.05  \n",
            "28           0.11  \n",
            "31           0.00  \n",
            "43           0.03  \n",
            "56           0.00  \n",
            "61           0.08  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows for 'Western Pacific' region\n",
        "df_western_pacific = df[df['WHO region'] == 'Western Pacific']\n",
        "print(\"Data for Western Pacific region:\\n\", df_western_pacific)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWKdY6XKe_h0"
      },
      "source": [
        "Extracts data pertaining to the 'Western Pacific' WHO region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj5fABgefCkV",
        "outputId": "fdac97ee-4e06-4ccc-d455-396ae192e97f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for Wine beverage type:\n",
            "     Year             WHO region  \\\n",
            "0   1986        Western Pacific   \n",
            "2   1985                 Africa   \n",
            "6   1987                 Africa   \n",
            "10  1987                 Africa   \n",
            "15  1987                 Africa   \n",
            "16  1984               Americas   \n",
            "20  1986        South-East Asia   \n",
            "26  1985                 Europe   \n",
            "31  1986        Western Pacific   \n",
            "34  1986                 Europe   \n",
            "43  1984        Western Pacific   \n",
            "49  1986                 Europe   \n",
            "52  1986  Eastern Mediterranean   \n",
            "55  1989               Americas   \n",
            "56  1987        Western Pacific   \n",
            "57  1989                 Europe   \n",
            "66  1987  Eastern Mediterranean   \n",
            "81  1985                 Europe   \n",
            "85  1985                 Africa   \n",
            "86  1986               Americas   \n",
            "87  1989  Eastern Mediterranean   \n",
            "89  1986  Eastern Mediterranean   \n",
            "90  1989                 Africa   \n",
            "96  1985                 Europe   \n",
            "97  1984        South-East Asia   \n",
            "98  1984                 Africa   \n",
            "99  1985        South-East Asia   \n",
            "\n",
            "                                              Country Beverage Types  \\\n",
            "0                                            Viet Nam           Wine   \n",
            "2                                        Cte d'Ivoire           Wine   \n",
            "6                                           Mauritius           Wine   \n",
            "10                                           Botswana           Wine   \n",
            "15                                      Guinea-Bissau           Wine   \n",
            "16                                         Costa Rica           Wine   \n",
            "20                                            Myanmar           Wine   \n",
            "26  United Kingdom of Great Britain and Northern I...           Wine   \n",
            "31                   Micronesia (Federated States of)           Wine   \n",
            "34                                 Russian Federation           Wine   \n",
            "43                                              China           Wine   \n",
            "49                                              Malta           Wine   \n",
            "52                                       Saudi Arabia           Wine   \n",
            "55                                           Suriname           Wine   \n",
            "56                                           Viet Nam           Wine   \n",
            "57                                            Croatia           Wine   \n",
            "66                                               Iraq           Wine   \n",
            "81                                        Netherlands           Wine   \n",
            "85                   Democratic Republic of the Congo           Wine   \n",
            "86                                            Bahamas           Wine   \n",
            "87                                               Iraq           Wine   \n",
            "89                                            Lebanon           Wine   \n",
            "90                                             Malawi           Wine   \n",
            "96                                         Luxembourg           Wine   \n",
            "97                                          Indonesia           Wine   \n",
            "98                                  Equatorial Guinea           Wine   \n",
            "99              Democratic People's Republic of Korea           Wine   \n",
            "\n",
            "    Display Value  \n",
            "0            0.00  \n",
            "2            1.62  \n",
            "6            0.13  \n",
            "10           0.20  \n",
            "15           0.07  \n",
            "16           0.06  \n",
            "20           0.00  \n",
            "26           1.36  \n",
            "31           0.00  \n",
            "34           0.80  \n",
            "43           0.03  \n",
            "49           1.49  \n",
            "52           0.00  \n",
            "55           0.04  \n",
            "56           0.00  \n",
            "57           5.10  \n",
            "66           0.01  \n",
            "81           2.54  \n",
            "85           0.01  \n",
            "86           1.83  \n",
            "87           0.01  \n",
            "89           0.70  \n",
            "90           0.01  \n",
            "96           7.38  \n",
            "97           0.00  \n",
            "98           0.00  \n",
            "99           0.00  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows for 'Wine'\n",
        "df_wine = df[df['Beverage Types'] == 'Wine']\n",
        "print(\"Data for Wine beverage type:\\n\", df_wine)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVEdPBhfe5rC"
      },
      "source": [
        "Displays data entries where the beverage type is 'Wine'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxIawiRcfFOE",
        "outputId": "86d689d8-9da3-425b-f3b8-482b69df0d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data with Display Value > 2.0:\n",
            "     Year             WHO region                           Country  \\\n",
            "3   1986               Americas                          Colombia   \n",
            "9   1984                 Africa                           Nigeria   \n",
            "17  1989                 Africa                        Seychelles   \n",
            "21  1989               Americas                        Costa Rica   \n",
            "22  1984                 Europe                           Romania   \n",
            "27  1984  Eastern Mediterranean                           Bahrain   \n",
            "30  1986                 Africa                      Sierra Leone   \n",
            "35  1985               Americas             Saint Kitts and Nevis   \n",
            "37  1986                 Europe                            Sweden   \n",
            "41  1986                 Europe                    Czech Republic   \n",
            "42  1984                 Europe                           Ukraine   \n",
            "46  1987               Americas               Trinidad and Tobago   \n",
            "51  1987                 Europe                           Finland   \n",
            "57  1989                 Europe                           Croatia   \n",
            "74  1986               Americas  Bolivia (Plurinational State of)   \n",
            "79  1989                 Europe                           Finland   \n",
            "81  1985                 Europe                       Netherlands   \n",
            "82  1987                 Europe                           Ireland   \n",
            "91  1989                 Europe                          Bulgaria   \n",
            "94  1985                 Europe                           Ukraine   \n",
            "96  1985                 Europe                        Luxembourg   \n",
            "\n",
            "   Beverage Types  Display Value  \n",
            "3            Beer           4.27  \n",
            "9           Other           6.10  \n",
            "17           Beer           2.23  \n",
            "21        Spirits           4.51  \n",
            "22        Spirits           2.67  \n",
            "27           Beer           2.22  \n",
            "30          Other           4.48  \n",
            "35        Spirits           2.24  \n",
            "37           Beer           3.04  \n",
            "41           Beer           6.82  \n",
            "42        Spirits           3.06  \n",
            "46        Spirits           2.26  \n",
            "51           Beer           3.88  \n",
            "57           Wine           5.10  \n",
            "74        Spirits           2.06  \n",
            "79          Other           2.09  \n",
            "81           Wine           2.54  \n",
            "82        Spirits           2.25  \n",
            "91           Beer           4.43  \n",
            "94        Spirits           3.06  \n",
            "96           Wine           7.38  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows where 'Display Value' is greater than 2.0\n",
        "df_high_consumption = df[df['Display Value'] > 2.0]\n",
        "print(\"Data with Display Value > 2.0:\\n\", df_high_consumption)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR65WONufHoE"
      },
      "source": [
        "Selects rows where the 'Display Value' exceeds 2.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGf07xAGfI2v",
        "outputId": "832dcfdf-c6a0-4517-a108-d69b3f4b11c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for the year 1986 and Wine beverage type:\n",
            "     Year             WHO region                           Country  \\\n",
            "0   1986        Western Pacific                          Viet Nam   \n",
            "20  1986        South-East Asia                           Myanmar   \n",
            "31  1986        Western Pacific  Micronesia (Federated States of)   \n",
            "34  1986                 Europe                Russian Federation   \n",
            "49  1986                 Europe                             Malta   \n",
            "52  1986  Eastern Mediterranean                      Saudi Arabia   \n",
            "86  1986               Americas                           Bahamas   \n",
            "89  1986  Eastern Mediterranean                           Lebanon   \n",
            "\n",
            "   Beverage Types  Display Value  \n",
            "0            Wine           0.00  \n",
            "20           Wine           0.00  \n",
            "31           Wine           0.00  \n",
            "34           Wine           0.80  \n",
            "49           Wine           1.49  \n",
            "52           Wine           0.00  \n",
            "86           Wine           1.83  \n",
            "89           Wine           0.70  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows for the year 1986 and 'Wine' beverage type\n",
        "df_1986_wine = df[(df['Year'] == 1986) & (df['Beverage Types'] == 'Wine')]\n",
        "print(\"Data for the year 1986 and Wine beverage type:\\n\", df_1986_wine)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n0-kU0SfLBu"
      },
      "source": [
        "Retrieves data for the year 1986 where the beverage type is 'Wine'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_XqT6GygAvj",
        "outputId": "ac9bf2cd-d4c2-4ab7-a991-c1d85e9b34ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for Viet Nam and Uruguay:\n",
            "     Year       WHO region   Country Beverage Types  Display Value\n",
            "0   1986  Western Pacific  Viet Nam           Wine           0.00\n",
            "1   1986         Americas   Uruguay          Other           0.50\n",
            "14  1985  Western Pacific  Viet Nam        Spirits           0.05\n",
            "28  1987  Western Pacific  Viet Nam           Beer           0.11\n",
            "56  1987  Western Pacific  Viet Nam           Wine           0.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows for 'Viet Nam' and 'Uruguay'\n",
        "df_countries = df[df['Country'].isin(['Viet Nam', 'Uruguay'])]\n",
        "print(\"Data for Viet Nam and Uruguay:\\n\", df_countries)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGIZYdp3gDEc"
      },
      "source": [
        "Extracts data entries for 'Viet Nam' and 'Uruguay'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vHQzAJJgFAc",
        "outputId": "3a858073-f9bc-4f8d-fd30-7245fa366334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for Wine and Beer beverage types:\n",
            "     Year             WHO region  \\\n",
            "0   1986        Western Pacific   \n",
            "2   1985                 Africa   \n",
            "3   1986               Americas   \n",
            "4   1987               Americas   \n",
            "6   1987                 Africa   \n",
            "10  1987                 Africa   \n",
            "11  1989               Americas   \n",
            "12  1985        Western Pacific   \n",
            "15  1987                 Africa   \n",
            "16  1984               Americas   \n",
            "17  1989                 Africa   \n",
            "19  1984                 Africa   \n",
            "20  1986        South-East Asia   \n",
            "23  1984                 Europe   \n",
            "26  1985                 Europe   \n",
            "27  1984  Eastern Mediterranean   \n",
            "28  1987        Western Pacific   \n",
            "31  1986        Western Pacific   \n",
            "32  1989                 Africa   \n",
            "34  1986                 Europe   \n",
            "36  1987  Eastern Mediterranean   \n",
            "37  1986                 Europe   \n",
            "41  1986                 Europe   \n",
            "43  1984        Western Pacific   \n",
            "45  1989                 Africa   \n",
            "48  1987               Americas   \n",
            "49  1986                 Europe   \n",
            "51  1987                 Europe   \n",
            "52  1986  Eastern Mediterranean   \n",
            "53  1984  Eastern Mediterranean   \n",
            "55  1989               Americas   \n",
            "56  1987        Western Pacific   \n",
            "57  1989                 Europe   \n",
            "64  1989               Americas   \n",
            "65  1989  Eastern Mediterranean   \n",
            "66  1987  Eastern Mediterranean   \n",
            "67  1989                 Africa   \n",
            "68  1989                 Africa   \n",
            "76  1985                 Africa   \n",
            "81  1985                 Europe   \n",
            "85  1985                 Africa   \n",
            "86  1986               Americas   \n",
            "87  1989  Eastern Mediterranean   \n",
            "88  1987  Eastern Mediterranean   \n",
            "89  1986  Eastern Mediterranean   \n",
            "90  1989                 Africa   \n",
            "91  1989                 Europe   \n",
            "96  1985                 Europe   \n",
            "97  1984        South-East Asia   \n",
            "98  1984                 Africa   \n",
            "99  1985        South-East Asia   \n",
            "\n",
            "                                              Country Beverage Types  \\\n",
            "0                                            Viet Nam           Wine   \n",
            "2                                        Cte d'Ivoire           Wine   \n",
            "3                                            Colombia           Beer   \n",
            "4                               Saint Kitts and Nevis           Beer   \n",
            "6                                           Mauritius           Wine   \n",
            "10                                           Botswana           Wine   \n",
            "11                                          Guatemala           Beer   \n",
            "12                   Lao People's Democratic Republic           Beer   \n",
            "15                                      Guinea-Bissau           Wine   \n",
            "16                                         Costa Rica           Wine   \n",
            "17                                         Seychelles           Beer   \n",
            "19                                              Kenya           Beer   \n",
            "20                                            Myanmar           Wine   \n",
            "23                                             Turkey           Beer   \n",
            "26  United Kingdom of Great Britain and Northern I...           Wine   \n",
            "27                                            Bahrain           Beer   \n",
            "28                                           Viet Nam           Beer   \n",
            "31                   Micronesia (Federated States of)           Wine   \n",
            "32                                          Mauritius           Beer   \n",
            "34                                 Russian Federation           Wine   \n",
            "36                                              Egypt           Beer   \n",
            "37                                             Sweden           Beer   \n",
            "41                                     Czech Republic           Beer   \n",
            "43                                              China           Wine   \n",
            "45                                           Zimbabwe           Beer   \n",
            "48                                          Nicaragua           Beer   \n",
            "49                                              Malta           Wine   \n",
            "51                                            Finland           Beer   \n",
            "52                                       Saudi Arabia           Wine   \n",
            "53                                             Kuwait           Beer   \n",
            "55                                           Suriname           Wine   \n",
            "56                                           Viet Nam           Wine   \n",
            "57                                            Croatia           Wine   \n",
            "64                   Bolivia (Plurinational State of)           Beer   \n",
            "65                                            Somalia           Beer   \n",
            "66                                               Iraq           Wine   \n",
            "67                                            Namibia           Beer   \n",
            "68                                             Uganda           Beer   \n",
            "76                                            Comoros           Beer   \n",
            "81                                        Netherlands           Wine   \n",
            "85                   Democratic Republic of the Congo           Wine   \n",
            "86                                            Bahamas           Wine   \n",
            "87                                               Iraq           Wine   \n",
            "88                                            Lebanon           Beer   \n",
            "89                                            Lebanon           Wine   \n",
            "90                                             Malawi           Wine   \n",
            "91                                           Bulgaria           Beer   \n",
            "96                                         Luxembourg           Wine   \n",
            "97                                          Indonesia           Wine   \n",
            "98                                  Equatorial Guinea           Wine   \n",
            "99              Democratic People's Republic of Korea           Wine   \n",
            "\n",
            "    Display Value  \n",
            "0            0.00  \n",
            "2            1.62  \n",
            "3            4.27  \n",
            "4            1.98  \n",
            "6            0.13  \n",
            "10           0.20  \n",
            "11           0.62  \n",
            "12           0.00  \n",
            "15           0.07  \n",
            "16           0.06  \n",
            "17           2.23  \n",
            "19           1.08  \n",
            "20           0.00  \n",
            "23           0.44  \n",
            "26           1.36  \n",
            "27           2.22  \n",
            "28           0.11  \n",
            "31           0.00  \n",
            "32           1.60  \n",
            "34           0.80  \n",
            "36           0.07  \n",
            "37           3.04  \n",
            "41           6.82  \n",
            "43           0.03  \n",
            "45           0.19  \n",
            "48           0.70  \n",
            "49           1.49  \n",
            "51           3.88  \n",
            "52           0.00  \n",
            "53           0.00  \n",
            "55           0.04  \n",
            "56           0.00  \n",
            "57           5.10  \n",
            "64           1.26  \n",
            "65           0.00  \n",
            "66           0.01  \n",
            "67           0.00  \n",
            "68           0.12  \n",
            "76           0.02  \n",
            "81           2.54  \n",
            "85           0.01  \n",
            "86           1.83  \n",
            "87           0.01  \n",
            "88           0.42  \n",
            "89           0.70  \n",
            "90           0.01  \n",
            "91           4.43  \n",
            "96           7.38  \n",
            "97           0.00  \n",
            "98           0.00  \n",
            "99           0.00  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('world_alcohol.csv')\n",
        "\n",
        "# Filter rows for 'Wine' and 'Beer'\n",
        "df_beverages = df[df['Beverage Types'].isin(['Wine', 'Beer'])]\n",
        "print(\"Data for Wine and Beer beverage types:\\n\", df_beverages)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ6QTjKLgHGz"
      },
      "source": [
        "Displays data where the beverage type is either 'Wine' or 'Beer'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afrO6bPOg1CC",
        "outputId": "4c241a98-f887-4524-9d74-2cfbbae30d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Country  Value\n",
            "0     USA     10\n",
            "1      UK     20\n",
            "2  Canada     30\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Country': ['USA', 'UK', 'Canada', 'Germany', 'France'],\n",
        "    'Value': [10, 20, 30, 40, 50]\n",
        "})\n",
        "\n",
        "# Filter rows where 'Country' is in the specified list\n",
        "filtered_df = df[df['Country'].isin(['USA', 'UK', 'Canada'])]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6vpDYxpg8p2"
      },
      "source": [
        "Select rows where the 'Country' column's value is either 'USA', 'UK', or 'Canada'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN8hHFs_g9Of",
        "outputId": "324b57c3-b1d8-43de-b671-3f7baf1d2b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Email\n",
            "0  user@example.com\n",
            "2   test@domain.com\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Email': ['user@example.com', 'invalid-email', 'test@domain.com']\n",
        "})\n",
        "\n",
        "# Regular expression pattern for valid emails\n",
        "pattern = r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$'\n",
        "\n",
        "# Filter rows with valid email addresses\n",
        "filtered_df = df[df['Email'].str.match(pattern)]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5pD6kG4g_aF"
      },
      "source": [
        "Select rows where the 'Email' column contains valid email addresses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOSWlEk2hC2X",
        "outputId": "2f7fa3de-4b42-4af2-ead3-54e363a359f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Name  Age\n",
            "1      Bob   22\n",
            "2  Charlie   29\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [17, 22, 29, 35]\n",
        "})\n",
        "\n",
        "# Filter rows where 'Age' is between 18 and 30\n",
        "filtered_df = df[df['Age'].between(18, 30)]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnNQ5bLdhEXr"
      },
      "source": [
        "Select rows where the 'Age' column's value is between 18 and 30 (inclusive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQJIhJgFhGju"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [24, 27, 35, 29],\n",
        "    'Salary': [48000, 52000, 45000, 49000]\n",
        "})\n",
        "\n",
        "# Filter rows where 'Age' > 25 and 'Salary' < 50000\n",
        "filtered_df = df[(df['Age'] > 25) & (df['Salary'] < 50000)]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5pwBVXJhIuN"
      },
      "source": [
        "Select rows where 'Age' is greater than 25 and 'Salary' is less than 50000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzPXy0GlhNCQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Address': ['123 St', np.nan, '456 Ave', '789 Blvd']\n",
        "})\n",
        "\n",
        "# Filter rows where 'Address' is not null\n",
        "filtered_df = df[df['Address'].notna()]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dal6HRhphOxr"
      },
      "source": [
        "Select rows where the 'Address' column is not null.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJhUDSHdh9GD",
        "outputId": "9a37f00b-c991-4c05-d8ea-c73a2c4a9a4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Name\n",
            "0    Alice\n",
            "2  Charlie\n",
            "3    David\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David']\n",
        "})\n",
        "\n",
        "# Filter rows where length of 'Name' > 4\n",
        "filtered_df = df[df['Name'].apply(len) > 4]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLs2pUnMiBj-"
      },
      "source": [
        " Select rows where the length of the 'Name' column is greater than 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQdY5PTYiEz2",
        "outputId": "d5d2df03-36d2-48f6-dc8a-b40d26ce38cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Value\n",
            "a     10\n",
            "c     30\n",
            "e     50\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with custom index\n",
        "df = pd.DataFrame({\n",
        "    'Value': [10, 20, 30, 40, 50]\n",
        "}, index=['a', 'b', 'c', 'd', 'e'])\n",
        "\n",
        "# Filter rows where index is in ['a', 'c', 'e']\n",
        "filtered_df = df.loc[['a', 'c', 'e']]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt-LXN5PiMAQ"
      },
      "source": [
        "Select rows where the index label is in the list ['a', 'c', 'e']."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNcJoJubiMgi",
        "outputId": "cf6e72b2-7395-4e38-e040-a1df73c78851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Product\n",
            "0   ProMax\n",
            "2  ProLite\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Product': ['ProMax', 'Ultra', 'ProLite', 'Standard']\n",
        "})\n",
        "\n",
        "# Filter rows where 'Product' contains 'Pro'\n",
        "filtered_df = df[df['Product'].str.contains('Pro')]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khje9QBNiOmv"
      },
      "source": [
        " Select rows where the 'Product' column contains the substring 'Pro'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hBI-t-IiQg4",
        "outputId": "c7cd4a6c-6398-40cc-b8a2-a0860ee4deb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Name\n",
            "0  Alice\n",
            "2   Anna\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Anna', 'Charlie']\n",
        "})\n",
        "\n",
        "# Filter rows where 'Name' starts with 'A'\n",
        "filtered_df = df[df['Name'].str.startswith('A')]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq5an3dxiTpz"
      },
      "source": [
        " Select rows where the 'Name' column starts with 'A'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnMTvCoeiU8c",
        "outputId": "283a2327-ef66-427a-bcc0-fd6a6030acca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Code\n",
            "0  A123\n",
            "2  A789\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Code': ['A123', 'B456', 'A789', 'C101']\n",
        "})\n",
        "\n",
        "# Filter rows where 'Code' matches pattern 'A\\d{3}'\n",
        "filtered_df = df[df['Code'].str.match(r'A\\d{3}')]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svYa_TSViW6p"
      },
      "source": [
        "Filter rows where a column's value matches a specific pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic1LOzFqiabY",
        "outputId": "645c5e4d-95e2-44bb-9baa-768c545201e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ID  Value\n",
            "1   2     20\n",
            "2   2     30\n",
            "4   4     50\n",
            "5   4     60\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'ID': [1, 2, 2, 3, 4, 4, 5],\n",
        "    'Value': [10, 20, 30, 40, 50, 60, 70]\n",
        "})\n",
        "\n",
        "# Filter rows where 'ID' is duplicated\n",
        "filtered_df = df[df.duplicated('ID', keep=False)]\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UklWyd8aid5Z"
      },
      "source": [
        "Select rows where the 'ID' column has duplicate values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQGwmDJIieVP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYSZca3nhill"
      },
      "source": [
        "1. Write a Pandas program to join the two given dataframes along rows and assign all data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRvK8FhAhnpC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "student_data1 = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "student_data2 = pd.DataFrame({\n",
        "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
        "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
        "        'marks': [201, 200, 198, 219, 201]})\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(\"-------------------------------------\")\n",
        "print(student_data2)\n",
        "print(\"\\nJoin the said two dataframes along rows:\")\n",
        "result_data = pd.concat([student_data1, student_data2])\n",
        "print(result_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyblXqDsh0S1"
      },
      "source": [
        "Join two DataFrames along rows and assign all data\n",
        "This exercise demonstrates how to concatenate two DataFrames vertically, stacking rows from the second DataFrame below the first. This method is useful for combining datasets with the same structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBJ1Drrch3u1"
      },
      "source": [
        "2. Write a Pandas program to join the two given dataframes along columns and assign all data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56BXHEJ8h8yN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "student_data1 = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "student_data2 = pd.DataFrame({\n",
        "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
        "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
        "        'marks': [201, 200, 198, 219, 201]})\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(\"-------------------------------------\")\n",
        "print(student_data2)\n",
        "print(\"\\nJoin the said two dataframes along columns:\")\n",
        "result_data = pd.concat([student_data1, student_data2], axis = 1)\n",
        "print(result_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCjgH72YiBJq"
      },
      "source": [
        "Here, you learn to concatenate two DataFrames horizontally, aligning them side by side. This technique is beneficial when combining datasets with the same index but different columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOyxcXZQiEuC"
      },
      "source": [
        "3. Write a Pandas program to append rows to an existing DataFrame and display the combined data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYATDHHDiMuE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "student_data1 = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "s6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'marks'])\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(\"\\nNew Row(s)\")\n",
        "print(s6)\n",
        "combined_data = student_data1.append(s6, ignore_index = True)\n",
        "print(\"\\nCombined Data:\")\n",
        "print(combined_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbXqWDMViNw9"
      },
      "source": [
        "Append rows to an existing DataFrame and display the combined data\n",
        "This task illustrates how to add new rows to an existing DataFrame using the append() method, which is helpful for expanding datasets incrementally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPt_gpZ0iQ3l"
      },
      "source": [
        "4. Write a Pandas program to append a list of dictioneries or series to a existing DataFrame and display the combined data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9KZ9ElfiaxZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "student_data1  = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "s6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'marks'])\n",
        "\n",
        "\n",
        "dicts = [{'student_id': 'S6', 'name': 'Scarlette Fisher', 'marks': 203},\n",
        "         {'student_id': 'S7', 'name': 'Bryce Jensen', 'marks': 207}]\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(\"\\nDictionary:\")\n",
        "print(s6)\n",
        "combined_data =  student_data1.append(dicts, ignore_index=True, sort=False)\n",
        "print(\"\\nCombined Data:\")\n",
        "print(combined_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsgB-BjEib1R"
      },
      "source": [
        "Append a list of dictionaries or series to an existing DataFrame and display the combined data\n",
        "Learn to extend a DataFrame by appending a list of dictionaries or series, allowing for flexible data addition from various sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYr5g5Ujie1G"
      },
      "source": [
        "5. Write a Pandas program to join the two given dataframes along rows and merge with another dataframe along the common column id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chQzJUbZiiT0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "student_data1 = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "student_data2 = pd.DataFrame({\n",
        "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
        "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
        "        'marks': [201, 200, 198, 219, 201]})\n",
        "\n",
        "exam_data = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13'],\n",
        "        'exam_id': [23, 45, 12, 67, 21, 55, 33, 14, 56, 83, 88, 12]})\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(student_data2)\n",
        "print(exam_data)\n",
        "\n",
        "print(\"\\nJoin first two said dataframes along rows:\")\n",
        "result_data = pd.concat([student_data1, student_data2])\n",
        "print(result_data)\n",
        "\n",
        "print(\"\\nNow join the said result_data and df_exam_data along student_id:\")\n",
        "final_merged_data = pd.merge(result_data, exam_data, on='student_id')\n",
        "print(final_merged_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9j4iIOCinkS"
      },
      "source": [
        "oin two DataFrames along rows and merge with another DataFrame along the common column 'id'\n",
        "This exercise combines vertical concatenation of two DataFrames and then merges the result with a third DataFrame based on a common 'id' column, demonstrating complex data integration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmZIHCPsiouB"
      },
      "source": [
        "6. Write a Pandas program to join the two dataframes using the common column of both dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClfxXY2ji_pe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "student_data1 = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "student_data2 = pd.DataFrame({\n",
        "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
        "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
        "        'marks': [201, 200, 198, 219, 201]})\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(student_data2)\n",
        "merged_data = pd.merge(student_data1, student_data2, on='student_id', how='inner')\n",
        "print(\"Merged data (inner join):\")\n",
        "print(merged_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaZj6upxjAZ-"
      },
      "source": [
        "Join two DataFrames using the common column of both DataFrames\n",
        "Here, you practice merging two DataFrames on a shared column, effectively combining related data based on common keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP7EjeO_jDKn"
      },
      "source": [
        "7. Write a Pandas program to join the two dataframes with matching records from both sides where available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ytAJjrWjGm4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "student_data1 = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "student_data2 = pd.DataFrame({\n",
        "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
        "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
        "        'marks': [201, 200, 198, 219, 201]})\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(student_data2)\n",
        "merged_data = pd.merge(student_data1, student_data2, on='student_id', how='outer')\n",
        "print(\"Merged data (outer join):\")\n",
        "print(merged_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYwFRCOrjJp9"
      },
      "source": [
        "Join two DataFrames with matching records from both sides where available\n",
        "This task involves performing an inner join to retain only the rows with matching keys in both DataFrames, ensuring the merged dataset contains complete records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX0PtEPzjMQp"
      },
      "source": [
        "8. Write a Pandas program to join (left join) the two dataframes using keys from left dataframe only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2ubQqddjSJe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
        "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']})\n",
        "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
        "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)\n",
        "print(\"\\nMerged Data (keys from data1):\")\n",
        "merged_data = pd.merge(data1, data2, how='left', on=['key1', 'key2'])\n",
        "print(merged_data)\n",
        "print(\"\\nMerged Data (keys from data2):\")\n",
        "merged_data = pd.merge(data2, data1, how='left', on=['key1', 'key2'])\n",
        "print(merged_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkpR1oQXjWyR"
      },
      "source": [
        "Perform a left join on two DataFrames using keys from the left DataFrame only\n",
        "Learn to execute a left join, keeping all records from the left DataFrame and adding matching records from the right DataFrame, filling in NaN for non-matching entries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCTlPR9GjYfw"
      },
      "source": [
        "9. Write a Pandas program to join two dataframes using keys from right dataframe only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bXM6KgYjydS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
        "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']})\n",
        "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
        "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)\n",
        "print(\"\\nMerged Data (keys from data2):\")\n",
        "merged_data = pd.merge(data1, data2, how='right', on=['key1', 'key2'])\n",
        "print(merged_data)\n",
        "print(\"\\nMerged Data (keys from data1):\")\n",
        "merged_data = pd.merge(data2, data1, how='right', on=['key1', 'key2'])\n",
        "print(merged_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz1tPCcIj0iO"
      },
      "source": [
        "Perform a right join on two DataFrames using keys from the right DataFrame only\n",
        "This exercise teaches how to conduct a right join, retaining all records from the right DataFrame and incorporating matching records from the left DataFrame, with NaN for non-matching entries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otDQPzK6j1v-"
      },
      "source": [
        "10. Write a Pandas program to merge two given datasets using multiple join keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62Tas1R4j4gw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
        "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']})\n",
        "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
        "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)\n",
        "print(\"\\nMerged Data (keys from data2):\")\n",
        "merged_data = pd.merge(data1, data2, how='right', on=['key1', 'key2'])\n",
        "print(merged_data)\n",
        "print(\"\\nMerged Data (keys from data1):\")\n",
        "merged_data = pd.merge(data2, data1, how='right', on=['key1', 'key2'])\n",
        "print(merged_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA98SG7nkDnK"
      },
      "source": [
        "Merge two datasets using multiple join keys\n",
        "Here, you practice merging two DataFrames based on multiple columns serving as composite keys, which is essential when a single column isn't unique enough to serve as a key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov8tUW8lkGdz"
      },
      "source": [
        "10. Write a Pandas program to create a new DataFrame based on existing series, using specified argument and override the existing columns names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ5kehBbkMYh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "s1 = pd.Series([0, 1, 2, 3], name='col1')\n",
        "s2 = pd.Series([0, 1, 2, 3])\n",
        "s3 = pd.Series([0, 1, 4, 5], name='col3')\n",
        "df = pd.concat([s1, s2, s3], axis=1, keys=['column1', 'column2', 'column3'])\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO8slibIkUDa"
      },
      "source": [
        "Combine the columns of two potentially differently-indexed DataFrames into a single result DataFrame\n",
        "This task involves aligning two DataFrames with different indices and combining their columns, demonstrating how to handle datasets that don't share the same indexing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fna4A5HRkWxP"
      },
      "source": [
        "12. Write a Pandas program to create a combination from two dataframes where a column id combination appears more than once in both dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4TRC43wkfYq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
        "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']})\n",
        "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
        "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)\n",
        "print(\"\\nMerged Data (many-to-many join case):\")\n",
        "result = pd.merge(data1, data2, on='key1')\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Xn9XE9kgcR"
      },
      "source": [
        "Create a combination from two DataFrames where a column id combination appears more than once in both DataFrames\n",
        "Learn to perform a many-to-many join, where combinations of key columns appear multiple times in both DataFrames, resulting in a Cartesian product of matching row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpendYZQkqC_"
      },
      "source": [
        "13. Write a Pandas program to combine the columns of two potentially differently-indexed DataFrames into a single result DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV0i_GllkzvV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
        "                      'B': ['B0', 'B1', 'B2']},\n",
        "                     index=['K0', 'K1', 'K2'])\n",
        "\n",
        "data2 = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
        "                      'D': ['D0', 'D2', 'D3']},\n",
        "                     index=['K0', 'K2', 'K3'])\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)\n",
        "print(\"\\nMerged Data (Joining on index):\")\n",
        "result = data1.join(data2)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ed2qBRgk3ld"
      },
      "source": [
        "Combine two DataFrames by filling null values in one DataFrame with non-null values from the other DataFrame\n",
        "This exercise shows how to merge two DataFrames and use the combine_first() method to fill NaN values in one DataFrame with corresponding non-null values from another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn6p4qX2k4fI"
      },
      "source": [
        "14. Write a Pandas program to merge two given dataframes with different columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwLX7wY_lSLH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
        "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']})\n",
        "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
        "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)\n",
        "print(\"\\nMerge two dataframes with different columns:\")\n",
        "result = pd.concat([data1,data2], axis=0, ignore_index=True)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQq126OSlTCs"
      },
      "source": [
        "Merge two DataFrames with different columns\n",
        "Here, you practice merging DataFrames that don't share all columns, resulting in a union of columns with NaN in places where data is missing, demonstrating flexibility in combining diverse datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVwRxMJKlXLH"
      },
      "source": [
        "15. Write a Pandas program to Combine two DataFrame objects by filling null values in one DataFrame with non-null values from other DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKQ3BKxslalN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1 = pd.DataFrame({'A': [None, 0, None], 'B': [3, 4, 5]})\n",
        "df2 = pd.DataFrame({'A': [1, 1, 3], 'B': [3, None, 3]})\n",
        "df1.combine_first(df2)\n",
        "print(\"Original DataFrames:\")\n",
        "print(df1)\n",
        "print(\"--------------------\")\n",
        "print(df2)\n",
        "print(\"\\nMerge two dataframes with different columns:\")\n",
        "result = df1.combine_first(df2)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvId4oGAlkyf"
      },
      "source": [
        "Merge two DataFrames with different columns and remove duplicate rows\n",
        "This task involves merging two DataFrames with differing columns and then removing any duplicate rows, ensuring the resulting DataFrame contains unique records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NX2O8XTjPw8"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge two DataFrames on a single column.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# merge two dataframes based on the 'key' column\n",
        "result = pd.merge(df1, df2, on='key')\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUbn-CXajVn6"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to perform an outer join on two DataFrames.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# outer join\n",
        "result = pd.merge(df1, df2, on='key', how='outer')\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsKFze08jXez"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program that performs a left join of two DataFrames.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K4'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# left join\n",
        "result = pd.merge(df1, df2, on='key', how='left')\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgPmIjQPjaor"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program that performs a right join of two DataFrames.\n",
        "\n",
        "import pandas as pd\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K4'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# right join\n",
        "result = pd.merge(df1, df2, on='key', how='right')\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIlLyNNmjfVc"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge two DataFrames on multiple columns.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data1 = {'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "\n",
        "data2 = {'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# merge two dataframes based on multiple keys\n",
        "result = pd.merge(df1, df2, on=['key1', 'key2'])\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvhz0VrBjkl-"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program that merges DataFrames with overlapping column names.\n",
        "\n",
        "import pandas as pd\n",
        "data1 = {'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "\n",
        "data2 = {'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# merge two dataframes with overlapping column names using suffixes\n",
        "result = pd.merge(df1, df2, on=['key1', 'key2'], suffixes=('_left', '_right'))\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdmEjCP2jov2"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge two DataFrames on their indexes.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Set the 'key' column as the index for both DataFrames\n",
        "df1 = df1.set_index('key')\n",
        "df2 = df2.set_index('key')\n",
        "\n",
        "# Merge the DataFrames based on their indexes\n",
        "merged_df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_QWPMFmjrq5"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge different column names in DataFrames.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Method 1: Using 'on' parameter with a common column\n",
        "result_on = pd.merge(df1, df2, on='key')\n",
        "print(\"Method 1 (using 'on'):\\n\", result_on)\n",
        "\n",
        "# Method 2: Using 'left_on' and 'right_on' with different column names\n",
        "data3 = {'key1': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data4 = {'key2': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "df3 = pd.DataFrame(data3)\n",
        "df4 = pd.DataFrame(data4)\n",
        "result_left_right = pd.merge(df3, df4, left_on='key1', right_on='key2')\n",
        "print(\"\\nMethod 2 (using 'left_on' and 'right_on'):\\n\", result_left_right)\n",
        "\n",
        "# Method 3: Using indexes\n",
        "df1 = df1.set_index('key')\n",
        "df2 = df2.set_index('key')\n",
        "result_index = pd.merge(df1, df2, left_index=True, right_index=True)\n",
        "print(\"\\nMethod 3 (using indexes):\\n\", result_index)\n",
        "\n",
        "# Method 4: Handling overlapping column names with suffixes\n",
        "data5 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data6 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai_new', 'Princi_new', 'Gaurav_new', 'Anuj_new'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj']}\n",
        "df5 = pd.DataFrame(data5)\n",
        "df6 = pd.DataFrame(data6)\n",
        "result_suffixes = pd.merge(df5, df6, on='key', suffixes=('_left', '_right'))\n",
        "print(\"\\nMethod 4 (handling overlapping column names with suffixes):\\n\",result_suffixes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qARnWlGkjwvr"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames with duplicate Keys\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Method 1: Using 'on' parameter with a common column\n",
        "result_on = pd.merge(df1, df2, on='key')\n",
        "print(\"Method 1 (using 'on'):\\n\", result_on)\n",
        "\n",
        "# Method 2: Using 'left_on' and 'right_on' with different column names\n",
        "data3 = {'key1': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data4 = {'key2': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "df3 = pd.DataFrame(data3)\n",
        "df4 = pd.DataFrame(data4)\n",
        "result_left_right = pd.merge(df3, df4, left_on='key1', right_on='key2')\n",
        "print(\"\\nMethod 2 (using 'left_on' and 'right_on'):\\n\", result_left_right)\n",
        "\n",
        "# Method 3: Using indexes\n",
        "df1 = df1.set_index('key')\n",
        "df2 = df2.set_index('key')\n",
        "result_index = pd.merge(df1, df2, left_index=True, right_index=True)\n",
        "print(\"\\nMethod 3 (using indexes):\\n\", result_index)\n",
        "\n",
        "# Method 4: Handling overlapping column names with suffixes\n",
        "data5 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data6 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai_new', 'Princi_new', 'Gaurav_new', 'Anuj_new'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj']}\n",
        "df5 = pd.DataFrame(data5)\n",
        "df6 = pd.DataFrame(data6)\n",
        "result_suffixes = pd.merge(df5, df6, on='key', suffixes=('_left', '_right'))\n",
        "print(\"\\nMethod 4 (handling overlapping column names with suffixes):\\n\",result_suffixes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd973z7wj1GH"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge multiple DataFrames on a common column.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "data3 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'City': ['Delhi', 'Bangalore', 'Chennai', 'Mumbai'],\n",
        "         'Salary': [10000, 20000, 30000, 40000]}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "df3 = pd.DataFrame(data3)\n",
        "\n",
        "# Merge multiple DataFrames\n",
        "merged_df = pd.merge(pd.merge(df1, df2, on='key'), df3, on='key')\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_5nJlOhj3rd"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames using join() on Index.\n",
        "\n",
        "import pandas as pd\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Set the 'key' column as the index for both DataFrames\n",
        "df1 = df1.set_index('key')\n",
        "df2 = df2.set_index('key')\n",
        "\n",
        "# Merge the DataFrames based on their indexes\n",
        "merged_df = df1.join(df2)\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLRn8jKlj6YB"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge with custom indicator to track source.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge with indicator\n",
        "merged_df = pd.merge(df1, df2, on='key', indicator=True)\n",
        "\n",
        "# Rename the indicator column\n",
        "merged_df = merged_df.rename(columns={'_merge': 'Source'})\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K50vze1qj-EW"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge two DataFrames using multiple keys and specific join conditions.\n",
        "\n",
        "import pandas as pd\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge with specific join conditions\n",
        "merged_df = pd.merge(df1, df2, on=['key1', 'key2'], how='inner')\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF7d5KQxkACv"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames using suffixes for overlapping columns.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames with overlapping column names\n",
        "data1 = {'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "         'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Name': ['Jai_new', 'Princi_new', 'Gaurav_new', 'Anuj_new']}  # Overlapping 'Name' column\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge the DataFrames using suffixes to distinguish overlapping columns\n",
        "result = pd.merge(df1, df2, on=['key1', 'key2'], suffixes=('_left', '_right'))\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt9G98YjkDnX"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames with custom sorting\n",
        "\n",
        "import pandas as pd\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge the DataFrames and sort by 'Age' in descending order\n",
        "merged_df = pd.merge(df1, df2, on='key').sort_values('Age', ascending=False)\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l59F5c7CkIEk"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames and drop duplicates.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge the DataFrames\n",
        "merged_df = pd.merge(df1, df2, on='key')\n",
        "\n",
        "# Drop duplicates (if any) based on all columns\n",
        "merged_df = merged_df.drop_duplicates()\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0zgzbkpkLSo"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames with missing data.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K4'],  # Introduce a missing key in data2\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge the DataFrames using an outer join to include all rows from both DataFrames\n",
        "merged_df = pd.merge(df1, df2, on='key', how='outer')\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFMLhqB_kQIr"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames and rename columns after merge.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge the DataFrames\n",
        "merged_df = pd.merge(df1, df2, on='key')\n",
        "\n",
        "# Rename columns\n",
        "merged_df = merged_df.rename(columns={'Name': 'Employee Name', 'Age': 'Employee Age'})\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCFdFDQtkS4b"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program to merge DataFrames on multiple columns with different names.\n",
        "\n",
        "import pandas as pd\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key1': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key2': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge DataFrames using 'left_on' and 'right_on'\n",
        "merged_df = pd.merge(df1, df2, left_on='key1', right_on='key2')\n",
        "\n",
        "merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v4GZ5HJkVlF"
      },
      "outputs": [],
      "source": [
        "# prompt: Write a Pandas program that merges DataFrames and select specific columns after merge.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames (replace with your actual data)\n",
        "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
        "         'Age': [27, 24, 22, 32]}\n",
        "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
        "         'Address': ['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'],\n",
        "         'Qualification': ['Btech', 'B.A', 'Bcom', 'B.hons']}\n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Merge the DataFrames\n",
        "merged_df = pd.merge(df1, df2, on='key')\n",
        "\n",
        "# Select specific columns after the merge\n",
        "selected_columns = merged_df[['Name', 'Qualification']]  # Example: Select 'Name' and 'Qualification'\n",
        "\n",
        "selected_columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXJBbWR2dTvi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Type': ['X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
        "        'Value': [1, 2, 3, 4, 5, 6]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Group by 'Category' and 'Type'\n",
        "print(\"\\nGroup by 'Category' and 'Type':\")\n",
        "grouped = df.groupby(['Category', 'Type']).sum()\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgFjRqhEgU4I"
      },
      "source": [
        "Group data by a single column and compute the sum\n",
        "Uses .groupby() to aggregate numeric columns by sum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNBZ9cl3gZMe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [10, 20, 30, 40, 50, 60]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Group by 'Category' and apply multiple aggregations\n",
        "print(\"\\nGroup by 'Category' and apply multiple aggregations:\")\n",
        "grouped = df.groupby('Category').agg(['sum', 'mean', 'max'])\n",
        "\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Yh4AcY1ggQB"
      },
      "source": [
        "Group by multiple columns and compute the mean\n",
        "Applies .groupby() on multiple columns and calculates the mean of numeric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtjVstnXgkB0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [5, 15, 25, 35, 45, 55]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Define custom aggregation function\n",
        "def custom_agg(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "# Group by 'Category' and apply custom aggregation\n",
        "print(\"\\nGroup by 'Category' and apply custom aggregation:\")\n",
        "grouped = df.groupby('Category').agg(custom_agg)\n",
        "\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2io4ns6CgohL"
      },
      "source": [
        "Apply multiple aggregation functions\n",
        "Uses .agg() to apply multiple aggregation functions (sum, mean, min, max) on grouped data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6xlRjq6gsc_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [1, 2, 3, 4, 5, 6]}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Group by 'Category'\n",
        "grouped = df.groupby('Category')\n",
        "# Filter groups where the sum of 'Value' > 5\n",
        "print(\"\\nFilter groups where the sum of 'Value' > 5\")\n",
        "filtered = grouped.filter(lambda x: x['Value'].sum() > 5)\n",
        "\n",
        "print(filtered)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFQVNDRfgxBl"
      },
      "source": [
        "Group data and count occurrences\n",
        "Counts the number of occurrences of each category using .count() or .size().\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L81rqIN6g0bX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [10, 20, 30, 40, 50, 60]}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Define function to apply to each group\n",
        "def scale_values(x):\n",
        "    return x / x.max()\n",
        "# Group by 'Category' and apply function\n",
        "print(\"\\nGroup by 'Category' and apply function:\")\n",
        "grouped = df.groupby('Category').transform(scale_values)\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydHCeRupg4te"
      },
      "source": [
        "Filter groups based on an aggregation condition\n",
        "Filters grouped data based on conditions like sum or count using .filter()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naI9GtxHg-3L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value1': [1, 2, 3, 4, 5, 6],\n",
        "        'Value2': [10, 20, 30, 40, 50, 60]}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Group by 'Category' and apply different aggregations\n",
        "print(\"\\nGroup by 'Category' and apply different aggregations:\")\n",
        "grouped = df.groupby('Category').agg({'Value1': 'sum', 'Value2': 'mean'})\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6imwqCSAhF5Y"
      },
      "source": [
        "Use transform to retain original DataFrame shape\n",
        "Uses .transform() to apply aggregation while maintaining the original DataFrame structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhsGyOSbhJIU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [5, 15, 25, 35, 45, 55]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Group by 'Category' and apply lambda function\n",
        "print(\"\\nGroup by 'Category' and apply lambda function:\")\n",
        "grouped = df.groupby('Category').agg(lambda x: x.max() - x.min())\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ig1uohPhPy4"
      },
      "source": [
        "Apply custom aggregation functions\n",
        "Defines and applies custom functions to grouped data using .apply()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWjd59DehUAA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Type': ['X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
        "        'Value': [1, 2, 3, 4, 5, 6]}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Group by 'Category' and 'Type'\n",
        "print(\"\\nGroup by 'Category' and 'Type':\")\n",
        "grouped = df.groupby(['Category', 'Type']).sum()\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUopEERmhgLj"
      },
      "source": [
        "Find the row with the maximum value in each group\n",
        "Uses .idxmax() or .apply(lambda x: x.nlargest(1)) to retrieve the row with the highest value in each group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7cqM5jwhjtA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value1': [10, 20, 30, 40, 50, 60],\n",
        "        'Value2': [100, 200, 300, 400, 500, 600]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Group by 'Category' and apply different functions\n",
        "print(\"\\nGroup by 'Category' and apply different functions:\")\n",
        "grouped = df.groupby('Category').agg({'Value1': 'mean', 'Value2': 'sum'})\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAroVT_Uhn6L"
      },
      "source": [
        "Calculate percentage of each value within a group\n",
        "Computes percentages within groups using .groupby().apply(lambda x: x / x.sum()).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87cnISE5hsDo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value1': [5, 10, 15, 20, 25, 30],\n",
        "        'Value2': [50, 100, 150, 200, 250, 300]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Group by 'Category' and apply named aggregations\n",
        "print(\"\\nGroup by 'Category' and apply named aggregations:\")\n",
        "grouped = df.groupby('Category').agg(\n",
        "    Value1_mean=('Value1', 'mean'),\n",
        "    Value2_sum=('Value2', 'sum')\n",
        ")\n",
        "\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEmI4Z55hzFE"
      },
      "source": [
        "Perform cumulative sum within groups\n",
        "Uses .cumsum() to get cumulative sums of values within each group.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZTgXjIkh0ah"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [1, 2, 3, 4, 5, 6]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Group by 'Category' and transform by calculating the mean\n",
        "print(\"\\nGroup by 'Category' and transform by calculating the mean:\")\n",
        "transformed = df.groupby('Category').transform('mean')\n",
        "print(transformed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw6CPfJFh7uS"
      },
      "source": [
        "Group by a categorical column and sort aggregated results\n",
        "Groups data and sorts the aggregated values using .sort_values().\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puorVs4Oh8ny"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value1': [1, 2, 3, 4, 5, 6],\n",
        "        'Value2': [10, 20, 30, 40, 50, 60]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Group by 'Category' and apply different functions using a dictionary\n",
        "print(\"\\nGroup by 'Category' and apply different functions using a dictionary:\")\n",
        "grouped = df.groupby('Category').agg({'Value1': 'sum', 'Value2': 'mean'})\n",
        "\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiBi_E0fiBIH"
      },
      "source": [
        "Compute rolling aggregates within each group\n",
        "Uses .rolling() with .groupby() to calculate rolling statistics within groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Or7cmog1iEDb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [10, 20, 30, 40, 50, 60]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "# Group by 'Category' and calculate the sum\n",
        "print(\"\\nGroup by 'Category' and calculate the sum:\")\n",
        "df['SumValue'] = df.groupby('Category')['Value'].transform('sum')\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjQS9xY5iI5g"
      },
      "source": [
        "Pivot tables for grouped data analysis\n",
        "Uses .pivot_table() as an alternative to .groupby() for multi-dimensional aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEKEqRjziO8a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with missing values\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [10, None, 30, 40, None, 60]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Fill missing values with 0 and then group by 'Category' and sum\n",
        "print(\"\\nFill missing values with 0 and then group by 'Category' and sum:\")\n",
        "grouped = df.fillna(0).groupby('Category').sum()\n",
        "\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDLmcPIKiT00"
      },
      "source": [
        "Aggregate based on time periods\n",
        "Groups data by time-based features (e.g., months, years) using pd.Grouper().\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7gbILzYiXJ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value1': [5, 10, 15, 20, 25, 30],\n",
        "        'Value2': [50, 100, 150, 200, 250, 300]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Sample DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Group by 'Category' and apply multiple named aggregations\n",
        "print(\"\\nGroup by 'Category' and apply multiple named aggregations:\")\n",
        "grouped = df.groupby('Category').agg(\n",
        "    Total_Value1=('Value1', 'sum'),\n",
        "    Average_Value2=('Value2', 'mean')\n",
        ")\n",
        "\n",
        "print(grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBiwV5voicG9"
      },
      "source": [
        "Hierarchical grouping and multi-index aggregation\n",
        "Uses multiple grouping keys to create hierarchical indexes and apply aggregations."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}